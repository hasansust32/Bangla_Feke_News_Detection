{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "04_fake_news_cleaning_word2vec_lstm_99_accuracy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": true,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfJltntgdDAN"
      },
      "source": [
        "# Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB_8irZQRkUw",
        "outputId": "e7ae36a3-64b0-4521-8dee-fe0e32730298"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsRqEzY_dDAZ"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "import re\n",
        "from wordcloud import WordCloud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5Ac0QZWo-KD"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Conv1D, MaxPool1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "import itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YapFgrosdDBf"
      },
      "source": [
        "# Exploring Fake News"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bNLlXdWdDBn"
      },
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/research/totaldata.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3arpkQWfdDCS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "7bdd7d7e-11c7-4273-902e-f1a429530159"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>articleID</th>\n",
              "      <th>content</th>\n",
              "      <th>headline</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>গত ১৭ সেপ্টেম্বর বাংলাদেশ কৃষি বিশ্ববিদ্যালয়ে ...</td>\n",
              "      <td>হট্টগোল করায় বাকৃবিতে দুইজন বরখাস্ত, ৬ জনকে শোকজ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>বাংলাদেশের বৃহৎ শ্রমবাজার মালয়েশিয়ায় আবার শ্রম...</td>\n",
              "      <td>মালয়েশিয়ায় কর্মী পাঠানোর ব্যবস্থা নেয়ার সুপারিশ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>নরসিংদীর মনোহরদীতে প্রেমের প্রস্তাবে রাজি না হ...</td>\n",
              "      <td>প্রেমের প্রস্তাবে রাজি না হওয়ায় স্কুলছাত্রীকে ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>সুপ্রিম কোর্টের হাইকোর্ট বিভাগের বিচারপতি আহমে...</td>\n",
              "      <td>মেডিয়েশনই মামলাজট নিরসনের পথ : বিচারপতি আহমেদ ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>মাদারীপুর সদরের উপজেলার লেকেরপাড়ে একটি বেসরকার...</td>\n",
              "      <td>টকশোতে বক্তব্য দিতে গিয়ে জাপা নেতার মৃত্যু</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...  label\n",
              "0           0  ...      1\n",
              "1           1  ...      1\n",
              "2           2  ...      1\n",
              "3           3  ...      1\n",
              "4           4  ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXeCGdsAdDDC"
      },
      "source": [
        "#Counting by Subjects \n",
        "#for key,count in fake.subject.value_counts().iteritems():\n",
        "#    print(f\"{key}:\\t{count}\")\n",
        "    \n",
        "#Getting Total Rows\n",
        "#print(f\"Total Records:\\t{fake.shape[0]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt3u2XJ5dDDs"
      },
      "source": [
        "#plt.figure(figsize=(8,5))\n",
        "#sns.countplot(\"subject\", data=fake)\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ_OV2opS0_Z"
      },
      "source": [
        "import nltk\n",
        "#nltk.download('stopwords')\n",
        "stopWords = []\n",
        "with open('/content/drive/MyDrive/research/bengali', 'r', encoding=\"utf8\") as f:\n",
        "    for row in f:  # iterate over the rows in the file\n",
        "        row = row.replace(\"\\n\", \"\")\n",
        "        stopWords.append(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwwnx8ZPUHXw",
        "outputId": "33ccca88-fd71-4c1f-c969-2b2e4a5ae72b"
      },
      "source": [
        "!pip install bnltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bnltk\n",
            "  Downloading https://files.pythonhosted.org/packages/0e/47/567ba84a5918c5b48cf61b205fd3ec60fa8cde228e18a3e7ba3c4ffbb8da/bnltk-0.7.6-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bnltk) (2.23.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from bnltk) (2.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bnltk) (1.19.5)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from bnltk) (0.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from bnltk) (2.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bnltk) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bnltk) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bnltk) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bnltk) (3.0.4)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (0.36.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (0.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (2.5.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (2.5.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (1.1.2)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (3.7.4.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (3.3.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (1.12.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (1.12)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (0.2.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (1.34.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (1.15.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (1.1.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (0.4.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (3.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->bnltk) (3.12.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->bnltk) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->bnltk) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->bnltk) (3.13)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->bnltk) (0.4.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->bnltk) (57.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->bnltk) (1.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->bnltk) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->bnltk) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->bnltk) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow->bnltk) (1.0.1)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow->bnltk) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->bnltk) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->bnltk) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->bnltk) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->bnltk) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->bnltk) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow->bnltk) (4.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow->bnltk) (3.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow->bnltk) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow->bnltk) (3.4.1)\n",
            "Installing collected packages: bnltk\n",
            "Successfully installed bnltk-0.7.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wjJakMydDF_"
      },
      "source": [
        "# Exploring Real news"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbXKpzl8dDHU"
      },
      "source": [
        "### Difference in Text\n",
        "Real news seems to have source of publication which is not present in fake news set\n",
        "\n",
        "Looking at the data:\n",
        "- most of text contains reuters information such as \"**WASHINGTON (Reuters)**\".\n",
        "- Some text are tweets from Twitter \n",
        "- Few text do not contain any publication info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tliOxHb7dDHg"
      },
      "source": [
        "# Cleaning Data\n",
        "Removing Reuters or Twitter Tweet information from the text \n",
        "\n",
        "- Text can be splitted only once at \" - \" which is always present after mentioning source of publication, this gives us publication part and text part\n",
        "- If we do not get text part, this means publication details was't given for that record\n",
        "- The Twitter tweets always have same source, a long text of max 259 characters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTxfBZkedDH2"
      },
      "source": [
        "#First Creating list of index that do not have publication part\n",
        "#unknown_publishers = []\n",
        "#for index,row in enumerate(real.text.values):\n",
        "#    try:\n",
        "#        record = row.split(\" -\", maxsplit=1)\n",
        "#        #if no text part is present, following will give error\n",
        "#        record[1]\n",
        "        #if len of piblication part is greater than 260\n",
        "        #following will give error, ensuring no text having \"-\" in between is counted\n",
        "#        assert(len(record[0]) < 260)\n",
        "#    except:\n",
        "#        unknown_publishers.append(index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx2SwfAURYGV"
      },
      "source": [
        "#Thus we have list of indices where publisher is not mentioned\n",
        "#lets check\n",
        "#real.iloc[unknown_publishers].text\n",
        "#true, they do not have text like \"WASHINGTON (Reuters)\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxRFushxRYGW"
      },
      "source": [
        "While looking at texts that do not contain publication info such as which reuter, we noticed one thing.\n",
        "\n",
        "**Text at index 8970 is empty**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu61NslfRYGW"
      },
      "source": [
        "#real.iloc[8970]\n",
        "#yep empty\n",
        "#will remove this soon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw7Ec258dDIx"
      },
      "source": [
        "#Seperating Publication info, from actual text\n",
        "#publisher = []\n",
        "#tmp_text = []\n",
        "#for index,row in enumerate(real.text.values):\n",
        "#    if index in unknown_publishers:\n",
        "#        #Add unknown of publisher not mentioned\n",
        "#        tmp_text.append(row)\n",
        "#        \n",
        "#        publisher.append(\"Unknown\")\n",
        "#        continue\n",
        "#    record = row.split(\" -\", maxsplit=1)\n",
        "#    publisher.append(record[0])\n",
        "#    tmp_text.append(record[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieCzo5pYdDJU"
      },
      "source": [
        "#Replace existing text column with new text\n",
        "#add seperate column for publication info\n",
        "#real[\"publisher\"] = publisher\n",
        "#real[\"text\"] = tmp_text\n",
        "\n",
        "#del publisher, tmp_text, record, unknown_publishers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGqTE2qtdDJo"
      },
      "source": [
        "#real.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaN23xONRYGZ"
      },
      "source": [
        "New column called \"Publisher\" has been added.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg9IeNc1RYGZ"
      },
      "source": [
        "#checking for rows with empty text like row:8970\n",
        "#[index for index,text in enumerate(real.text.values) if str(text).strip() == '']\n",
        "#seems only one :)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN729HObRYGa"
      },
      "source": [
        "#dropping this record\n",
        "#real = real.drop(8970, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7i9_-sXRYGb"
      },
      "source": [
        "# checking for the same in fake news\n",
        "#empty_fake_index = [index for index,text in enumerate(fake.text.values) if str(text).strip() == '']\n",
        "#print(f\"No of empty rows: {len(empty_fake_index)}\")\n",
        "#fake.iloc[empty_fake_index].tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDExchHqRYGc"
      },
      "source": [
        "**630 Rows in Fake news with empty text**\n",
        "\n",
        "Also noticed fake news have a lot of CPATIAL-CASES. Could preserve Cases of letters, but as we are using Google's pretrained word2vec vectors later on, which haswell-formed lower cases word. We will contert to lower case.\n",
        "\n",
        "The text for these rows seems to be present in title itself. Lets merge title and text to solve these cases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1-s152ydDJ-"
      },
      "source": [
        "#Looking at publication Information\n",
        "# Checking if Some part of text has been included as publisher info... No such cases it seems :)\n",
        "\n",
        "# for name,count in real.publisher.value_counts().iteritems():\n",
        "#     print(f\"Name: {name}\\nCount: {count}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ncknf-UPdDKQ"
      },
      "source": [
        "#Getting Total Rows\n",
        "#print(f\"Total Records:\\t{real.shape[0]}\")\n",
        "\n",
        "#Counting by Subjects \n",
        "#for key,count in real.subject.value_counts().iteritems():\n",
        "#  print(f\"{key}:\\t{count}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7hyf09XdDKg"
      },
      "source": [
        "#sns.countplot(x=\"subject\", data=real)\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31IETzH6dDLR"
      },
      "source": [
        "# Preprocessing Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJpU7O2OdDLT"
      },
      "source": [
        "# Adding class Information\n",
        "#real[\"class\"] = 1\n",
        "#fake[\"class\"] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYj4Dnm7dDLh"
      },
      "source": [
        "#Combining Title and Text\n",
        "dataset[\"text\"] = dataset[\"content\"] + \" \" + dataset[\"headline\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiBm_dDWdDLw"
      },
      "source": [
        "# Subject is diffrent for real and fake thus dropping it\n",
        "# Aldo dropping Date, title and Publication Info of real\n",
        "#real = real.drop([\"subject\", \"date\",\"title\",  \"publisher\"], axis=1)\n",
        "#fake = fake.drop([\"subject\", \"date\", \"title\"], axis=1)\n",
        "dataset = dataset.drop([\"Unnamed: 0\", \"articleID\", \"headline\", \"content\"], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_L4CePKdDME"
      },
      "source": [
        "#Combining both into new dataframe\n",
        "#data = real.append(fake, ignore_index=True)\n",
        "#del real, fake"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R74pjsDYkz34"
      },
      "source": [
        "# Download following if not downloaded in local machine\n",
        "\n",
        "# nltk.download('stopwords')\n",
        "# nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOsIM3N-RYGy"
      },
      "source": [
        "Removing StopWords, Punctuations and single-character words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkKRZdJ2TYLD",
        "outputId": "bb33ca32-0557-480b-965c-a75a63c111e5"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from bnltk.tokenize import Tokenizers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H07kA_z6dDMX"
      },
      "source": [
        "y = dataset[\"label\"].values\n",
        "#Converting X to format acceptable by gensim, removing annd punctuation stopwords in the process\n",
        "X = []\n",
        "#stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
        "#tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
        "tokenizer = Tokenizers()\n",
        "for par in dataset[\"text\"].values:\n",
        "    tmp = []\n",
        "    #sentences = nltk.sent_tokenize(par)\n",
        "#    for sent in sentences:\n",
        "    tokens = tokenizer.bn_word_tokenizer(par)\n",
        "    filtered_words = [w.strip() for w in tokens if w not in stopWords and len(w) > 1]\n",
        "    tmp.extend(filtered_words)\n",
        "    X.append(tmp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32ECOr9p1spI"
      },
      "source": [
        "def plot_confusion_matrix(cm,classes,normalize=False,title='Confusion Matrix', cmap = plt.cm.Greens):\n",
        "    plt.imshow(cm,interpolation = 'nearest',cmap = cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks,classes,rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    \n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n",
        "        print(\"Normalized CM\")\n",
        "    else:\n",
        "        print(\"CM not normalized\")\n",
        "        \n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "ZFLUPXGodDMv"
      },
      "source": [
        "### Vectorization -- Word2Vec\n",
        "\n",
        "Word2Vec is one of the most popular technique to learn word embeddings using shallow neural network. It was developed by Tomas Mikolov in 2013 at Google.\n",
        "\n",
        "Word embedding is the most popular representation of document vocabulary. It is capable of capturing context of a word in a document, semantic and syntactic similarity, relation with other words, etc.\n",
        "\n",
        "[Here](https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa) is a nice article about it.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHKIgurRdDM2"
      },
      "source": [
        "#### Let's create and check our own Word2Vec model with **gensim**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoQRvjexdDM5"
      },
      "source": [
        "import gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JpCLfaldDNW"
      },
      "source": [
        "#Dimension of vectors we are generating\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "#Creating Word Vectors by Word2Vec Method (takes time...)\n",
        "w2v_model = gensim.models.Word2Vec(sentences=X, size=EMBEDDING_DIM, window=5, min_count=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP1nyaGqdDNr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c9efb96-caf2-4805-f473-c85c336386a8"
      },
      "source": [
        "#vocab size\n",
        "len(w2v_model.wv.vocab)\n",
        "\n",
        "#We have now represented each of 122248 words by a 100dim vector."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125598"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iloSEX4NdDN_"
      },
      "source": [
        "### Exploring Vectors\n",
        "\n",
        "Lets checkout these vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_7dwRJ7RYG1",
        "outputId": "99b8cc48-9279-4973-afb6-fafbf2f7087e"
      },
      "source": [
        "#see a sample vector for random word, lets say সুপ্রিম\n",
        "w2v_model[\"সুপ্রিম\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.90750074, -1.4755845 , -2.572456  ,  2.8242438 , -0.86491394,\n",
              "        0.6444068 ,  1.7847822 , -0.13165455,  0.11252116,  0.5189889 ,\n",
              "       -2.8908105 ,  0.30107132,  0.17667034, -0.33088368,  0.37112138,\n",
              "        0.01856638,  1.7828307 ,  0.75651205, -0.6888059 ,  1.4567609 ,\n",
              "        0.6633846 ,  1.142321  ,  0.01311825, -1.073162  ,  0.45005718,\n",
              "        0.18277425, -1.1440268 ,  1.5136646 ,  0.01842755, -0.98905665,\n",
              "       -0.3694203 , -1.3922346 ,  0.9030151 , -0.37200373, -1.00134   ,\n",
              "        0.0522076 ,  0.1176045 ,  0.03449881,  1.2026168 ,  0.97143215,\n",
              "        0.37414572, -0.07951898, -1.5175784 ,  0.18149206,  0.52065235,\n",
              "        1.0199656 , -0.02823722,  0.89417154,  0.05752806,  0.7380109 ,\n",
              "        0.5258152 ,  0.13869426, -0.9588831 , -0.50009894, -1.0954757 ,\n",
              "        2.698482  , -0.86620164, -0.3126413 , -1.1487119 ,  0.8589577 ,\n",
              "        0.00621035,  2.1597288 , -1.5139424 ,  1.515407  ,  2.048537  ,\n",
              "        1.4232441 ,  0.3698083 ,  1.3593785 , -0.9515993 ,  0.48125514,\n",
              "       -0.9663791 ,  1.1081471 ,  0.26851338, -0.49428213,  0.99025846,\n",
              "        0.5230432 , -0.12753415,  1.580535  , -0.64408106, -0.23401149,\n",
              "       -0.32868725,  1.4975432 ,  1.143196  , -0.16443445,  0.07262724,\n",
              "        0.70409817,  0.9565993 ,  0.9917665 , -1.3088505 , -1.4256562 ,\n",
              "       -1.2375147 ,  0.06801409,  1.8210627 ,  2.2724874 ,  0.62542325,\n",
              "       -0.49654636, -1.3470055 , -1.6279788 ,  0.39942876,  0.0863541 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3eymov_dDOC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebbc543b-3576-49d8-8e6d-1086b9322cf8"
      },
      "source": [
        "w2v_model.wv.most_similar(\"সেপ্টেম্বর\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('সেপ্টম্বর', 0.7795805335044861),\n",
              " ('২৪নং', 0.7410720586776733),\n",
              " ('রিলেন', 0.7220916748046875),\n",
              " ('গড়লো', 0.7192182540893555),\n",
              " ('অভিযানও', 0.7157152891159058),\n",
              " ('ধাঁধাটি', 0.705436110496521),\n",
              " ('খননকাজের', 0.698965311050415),\n",
              " ('প্রসারসহ', 0.6886398792266846),\n",
              " ('ডায়ানাসহ', 0.6850882768630981),\n",
              " ('সেপ্টেম্বের', 0.684147834777832)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZKs8h6wRYG4"
      },
      "source": [
        "#Feeding US Presidents\n",
        "#w2v_model.wv.most_similar(positive=[\"trump\",\"obama\", \"clinton\"])\n",
        "#First was Bush"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jDnzu5Htzsp"
      },
      "source": [
        "**Looking at the similar words, vectors are well formed for these words :)**\n",
        "\n",
        "\n",
        "These Vectors will be passed to LSTM/GRU instead of words. 1D-CNN can further be used to extract features from the vectors. \n",
        "\n",
        "\n",
        "Keras has implementation called \"**Embedding Layer**\" which would create word embeddings(vectors). Since we did that with gensim's word2vec, we will load these vectors into embedding layer and make the layer non-trainable.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-v0fHyjRYG5"
      },
      "source": [
        "We cannot pass string words to embedding layer, thus need some way to represent each words by numbers.\n",
        "\n",
        "Tokenizer can represent each word by number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nQ8aN_brt-m"
      },
      "source": [
        "# Tokenizing Text -> Repsesenting each word by a number\n",
        "# Mapping of orginal word to number is preserved in word_index property of tokenizer\n",
        "\n",
        "#Tokenized applies basic processing like changing it yo lower case, explicitely setting that as False\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "\n",
        "X = tokenizer.texts_to_sequences(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F08MoRH-RYG6",
        "outputId": "e2a7f333-3ee1-4e0a-be49-f7ba2bf5f320"
      },
      "source": [
        "# lets check the first 10 words of first news\n",
        "#every word has been represented with a number\n",
        "X[0][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[21, 466, 7, 3, 1493, 1576, 9511, 6686, 761, 19581]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tGDdh1ARYG7",
        "outputId": "9d299738-d90c-4bf0-a31e-b1d7dee0a202"
      },
      "source": [
        "#Lets check few word to numerical replesentation\n",
        "#Mapping is preserved in dictionary -> word_index property of instance\n",
        "word_index = tokenizer.word_index\n",
        "for word, num in word_index.items():\n",
        "    print(f\"{word} -> {num}\")\n",
        "    if num == 10:\n",
        "        break        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "হয়েছে -> 1\n",
            "এক -> 2\n",
            "বাংলাদেশ -> 3\n",
            "হয়ে -> 4\n",
            "সময় -> 5\n",
            "কথা -> 6\n",
            "সেপ্টেম্বর -> 7\n",
            "দিয়ে -> 8\n",
            "যায় -> 9\n",
            "জানান -> 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZGjYjAxRYG8"
      },
      "source": [
        "**Notice it starts with 1**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Loo09CpGRYG8"
      },
      "source": [
        "We can pass numerical representation of words into neural network.\n",
        "\n",
        "We can use Many-To-One (Sequence-To-Word) Model of RNN, as we have many words in news as input and one output ie Probability of being Real.\n",
        "\n",
        "For Many-To-One model, lets use a fixed size input. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQYGbmRZrtrO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "4e740652-3d8d-404e-f453-f3245080bb55"
      },
      "source": [
        "# For determining size of input...\n",
        "\n",
        "# Making histogram for no of words in news shows that most news article are under 700 words.\n",
        "# Lets keep each news small and truncate all news to 700 while tokenizing\n",
        "plt.hist([len(x) for x in X], bins=500)\n",
        "plt.show()\n",
        "\n",
        "# Its heavily skewed. There are news with 5000 words? Lets truncate these outliers :) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObfiqLhyrtxY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db580263-f0dd-4a30-a2eb-839ee48d87ee"
      },
      "source": [
        "nos = np.array([len(x) for x in X])\n",
        "len(nos[nos  < 700])\n",
        "# Out of 48k news, 44k have less than 700 words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11211"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf-4aQnqrt6M"
      },
      "source": [
        "#Lets keep all news to 700, add padding to news with less than 700 words and truncating long ones\n",
        "maxlen = 700 \n",
        "\n",
        "#Making all news of size maxlen defined above\n",
        "X = pad_sequences(X, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ObM97P4RYG-",
        "outputId": "121e2f5d-0e7e-464d-b2b1-23d9d01b43e4"
      },
      "source": [
        "#all news has 700 words (in numerical form now). If they had less words, they have been padded with 0\n",
        "# 0 is not associated to any word, as mapping of words started from 1\n",
        "# 0 will also be used later, if unknows word is encountered in test set\n",
        "len(X[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "700"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q3cFF-N2Mix"
      },
      "source": [
        "# Adding 1 because of reserved 0 index\n",
        "# Embedding Layer creates one more vector for \"UNKNOWN\" words, or padded words (0s). This Vector is filled with zeros.\n",
        "# Thus our vocab size inceeases by 1\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFjoigbq43SM"
      },
      "source": [
        "# Function to create weight matrix from word2vec gensim model\n",
        "def get_weight_matrix(model, vocab):\n",
        "    # total vocabulary size plus 0 for unknown words\n",
        "    vocab_size = len(vocab) + 1\n",
        "    # define weight matrix dimensions with all 0\n",
        "    weight_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
        "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
        "    for word, i in vocab.items():\n",
        "        weight_matrix[i] = model[word]\n",
        "    return weight_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbAG_PQeRYG_"
      },
      "source": [
        "We Create a matrix of mapping between word-index and vectors. We use this as weights in embedding layer\n",
        "\n",
        "Embedding layer accepts numecical-token of word and outputs corresponding vercor to inner layer.\n",
        "\n",
        "It sends vector of zeros to next layer for unknown words which would be tokenized to 0.\n",
        "\n",
        "\n",
        "Input length of Embedding Layer is the length of each news (700 now due to padding and truncating)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2etO3jIrtvM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "bfab570f-c61d-4035-eab6-51d3f5df6436"
      },
      "source": [
        "#Getting embedding vectors from word2vec and usings it as weights of non-trainable keras embedding layer\n",
        "embedding_vectors = get_weight_matrix(w2v_model, word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-75ddb15b1e0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Getting embedding vectors from word2vec and usings it as weights of non-trainable keras embedding layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0membedding_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_weight_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-41-d9da2bd6ecb8>\u001b[0m in \u001b[0;36mget_weight_matrix\u001b[0;34m(model, vocab)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# step vocab, store vectors using the Tokenizer's integer mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mweight_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mweight_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36mnew_func1\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1420\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m                 )\n\u001b[0;32m-> 1422\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_func1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \"\"\"\n\u001b[0;32m-> 1103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method will be removed in 4.0.0, use self.wv.__contains__() instead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"word 'bengal' not in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5zvTNuoRYHA"
      },
      "source": [
        "#Defining Neural Network\n",
        "model = Sequential()\n",
        "#Non-trainable embeddidng layer\n",
        "model.add(Embedding(vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_vectors], input_length=maxlen, trainable=False))\n",
        "#LSTM \n",
        "model.add(LSTM(units=128))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "del embedding_vectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9QlV7NrID0_"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II-pr_sgHpcX"
      },
      "source": [
        "#Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkCiftes3JD6"
      },
      "source": [
        "model.fit(X_train, y_train, validation_split=0.3, epochs=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swVt7TjQzNCM"
      },
      "source": [
        "#Prediction is in probability of news being real, so converting into classes\n",
        "# Class 0 (Fake) if predicted prob < 0.5, else class 1 (Real)\n",
        "y_pred = (model.predict(X_test) >= 0.5).astype(\"int\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l6MGjUTJntM"
      },
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAx6hEfbJqvm"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ncDQMKRyE55"
      },
      "source": [
        "del model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC8v4HlZdLcu"
      },
      "source": [
        "### Using Pre-Trained Word2Vec Vectors\n",
        "\n",
        "**Needs 12GB RAM and 4GB HardDisk Space **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5k8KpZGKfTf"
      },
      "source": [
        "Now, instead of creating word vectors, let us use pre-trained vectors trained on part of **Google News dataset** (about 100 billion words). The model contains 300-dimensional vectors for 3 million words and phrases.  Source: https://code.google.com/archive/p/word2vec/\n",
        "\n",
        "**Please download model file from**: https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing\n",
        "\n",
        "\n",
        "Or add Dataset from https://www.kaggle.com/sandreds/googlenewsvectorsnegative300\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fqG4DyMRYHE",
        "outputId": "ceaf67a3-e9b0-411c-d89e-b2bcd1c98941"
      },
      "source": [
        "#invoke garbage collector to free ram\n",
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36518"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk_AEI94LmHI"
      },
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh9N8WePRYHF"
      },
      "source": [
        "# Takes RAM \n",
        "word_vectors = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/research/word2vec.txt')\n",
        "EMBEDDING_DIM=100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLcTApQpgXpe"
      },
      "source": [
        "### Exploring these trained Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esvjlzgzgUH5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f295f94-4aec-411e-e7f4-f48fa4e7ecc3"
      },
      "source": [
        "word_vectors.most_similar('বাংলাদেশ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(\"'বাংলাদেশ\", 0.7342807650566101),\n",
              " ('বাংলদেশ', 0.7298583984375),\n",
              " ('বংলাদেশ', 0.7064653038978577),\n",
              " ('বিশ্ব', 0.6834918260574341),\n",
              " ('জাপান', 0.6717811822891235),\n",
              " ('এশিয়ান', 0.6656081080436707),\n",
              " ('বাংলাদেশের', 0.6640017628669739),\n",
              " ('জাতীয়', 0.65651935338974),\n",
              " ('পাকিস্তান', 0.6507294774055481),\n",
              " ('ভারত', 0.639733612537384)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2ZIES6SgUMr"
      },
      "source": [
        "# word_vectors.most_similar('fbi')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbRzkWt9gUaJ"
      },
      "source": [
        "# word_vectors.most_similar('Republic')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdkVbKXqfJGh"
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    try:\n",
        "        embedding_vector = word_vectors[word]\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    except KeyError:\n",
        "        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)\n",
        "\n",
        "#del word_vectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiNvZs-E3cw1"
      },
      "source": [
        "#Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoSJl84gLZi8"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, output_dim=EMBEDDING_DIM, weights=[embedding_matrix], input_length=maxlen, trainable=False))\n",
        "model.add(Conv1D(activation='relu', filters=4, kernel_size=4))\n",
        "model.add(MaxPool1D())\n",
        "model.add(LSTM(units=128))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "del embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzvS8m5LLZtu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c695b5ca-23fe-4d52-e899-84217d63ae62"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 700, 100)          12547600  \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 697, 4)            1604      \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 348, 4)            0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               68096     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 12,617,429\n",
            "Trainable params: 69,829\n",
            "Non-trainable params: 12,547,600\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMJklhVAjNGZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "410bf5c8-dadd-4500-d607-09087c7d5c32"
      },
      "source": [
        "model.fit(X_train, y_train, validation_split=0.3, epochs=12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "188/188 [==============================] - 38s 24ms/step - loss: 0.2578 - acc: 0.8919 - val_loss: 0.2269 - val_acc: 0.9164\n",
            "Epoch 2/12\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.2008 - acc: 0.9189 - val_loss: 0.1972 - val_acc: 0.9273\n",
            "Epoch 3/12\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.1778 - acc: 0.9299 - val_loss: 0.1793 - val_acc: 0.9285\n",
            "Epoch 4/12\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.1567 - acc: 0.9365 - val_loss: 0.1724 - val_acc: 0.9304\n",
            "Epoch 5/12\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.1449 - acc: 0.9427 - val_loss: 0.1678 - val_acc: 0.9335\n",
            "Epoch 6/12\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.1284 - acc: 0.9484 - val_loss: 0.1723 - val_acc: 0.9355\n",
            "Epoch 7/12\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.1259 - acc: 0.9508 - val_loss: 0.1917 - val_acc: 0.9343\n",
            "Epoch 8/12\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.1115 - acc: 0.9578 - val_loss: 0.1899 - val_acc: 0.9343\n",
            "Epoch 9/12\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.1036 - acc: 0.9630 - val_loss: 0.2147 - val_acc: 0.9363\n",
            "Epoch 10/12\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0930 - acc: 0.9610 - val_loss: 0.1977 - val_acc: 0.9343\n",
            "Epoch 11/12\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0831 - acc: 0.9688 - val_loss: 0.2076 - val_acc: 0.9254\n",
            "Epoch 12/12\n",
            "188/188 [==============================] - 4s 22ms/step - loss: 0.0731 - acc: 0.9732 - val_loss: 0.2142 - val_acc: 0.9370\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f58d40e33d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaUCmKYojQJS"
      },
      "source": [
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkZtLGNYjXnu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c04def30-fd76-4363-fd5e-16c91e3dd7f1"
      },
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix: \n",
            " [[ 249  103]\n",
            " [  75 2432]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEer0v19-JEQ"
      },
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix: \\n\", cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "xs-1BoQ414UH",
        "outputId": "b5b17167-ab46-4469-8bad-9d59da943ce6"
      },
      "source": [
        "# Plot Confusion Matrix\n",
        "plot_confusion_matrix(cm,classes = ['Fake','Real'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CM not normalized\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVYAAAEmCAYAAAA5jbhCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xd473H8c93JkhIkHtCLm5xiai4JXFtqkWiCK27EsoJSqlqe1Qd1OW8WocqdVeKuB2qCImQRh3UNVciQVIhRCQSQSVuid/5Y62JncvM7Im1Z6+Z/X3ntV6z97OevdZvzWR+86xnPetZigjMzCw7VeUOwMysuXFiNTPLmBOrmVnGnFjNzDLmxGpmljEnVjOzjDmx2ipJaiXpIUkfSbr3G2znKEmPZRlbOUh6RNLQcsdhTYMTaxMn6UhJ4yR9ImlOmgB2y2DTBwOdgfYRccjqbiQi7oiIvTOIZzmSBkoKSfevUL5tWv5Ekds5X9Lt9dWLiMERcetqhmsVxom1CZP0c+CPwH+TJMEewDXAkAw23xN4PSKWZLCtUnkf2FlS+4KyocDrWe1ACf+eWMNEhJcmuADrAZ8Ah9RRZy2SxPtuuvwRWCtdNxB4BzgTmAfMAY5L1/0W+AL4Mt3H8cD5wO0F294ICKBF+v5Y4A3g38BM4KiC8qcLPrcL8CLwUfp1l4J1TwAXAv9Mt/MY0KGWY6uJ/zrglLSsGpgNnAs8UVD3CuBt4GNgPLB7Wj5oheOcXBDHxWkcnwKbpWUnpOuvBe4r2P7vgbGAyv3/wks+Fv8lbrp2BloC99dR5zfAAKAvsC3QDzinYH0XkgS9IUnyvFpS24g4j6QV/L8R0ToibqorEEnrAFcCgyOiDUnynLSKeu2AkWnd9sAfgJErtDiPBI4DOgFrAr+oa9/AbcAx6et9gCkkf0QKvUjyPWgH3AncK6llRIxe4Ti3LfjM0cAwoA3w1grbOxPYRtKxknYn+d4NjQjfH26AuwKasvbA/Kj7VP0o4IKImBcR75O0RI8uWP9luv7LiBhF0mrbYjXj+QroI6lVRMyJiFdWUef7wPSIGB4RSyLiLuBVYP+COn+JiNcj4lPgHpKEWKuIeAZoJ2kLkgR72yrq3B4RC9J9XkbSkq/vOG+JiFfSz3y5wvYWk3wf/wDcDvw0It6pZ3tWQZxYm64FQAdJLeqoswHLt7beSsuWbWOFxLwYaN3QQCJiEXAYcBIwR9JISVsWEU9NTBsWvH9vNeIZDpwKfIdVtOAl/ULStHSEw4ckrfQO9Wzz7bpWRsTzJF0fIvkDYLaME2vT9SzwOXBgHXXeJbkIVaMHK58mF2sRsHbB+y6FKyPi0YjYC+hK0gq9sYh4amKavZox1RgO/AQYlbYml0lP1X8FHAq0jYj1Sfp3VRN6Ldus87Re0ikkLd930+2bLePE2kRFxEckF2mulnSgpLUlrSFpsKRL0mp3AedI6iipQ1q/3qFFtZgE7CGph6T1gF/XrJDUWdKQtK/1c5Iuha9WsY1RwObpELEWkg4DegMPr2ZMAETETODbJH3KK2oDLCEZQdBC0rnAugXr5wIbNeTKv6TNgYuAH5F0CfxKUp1dFlZZnFibsLS/8OckF6TeJzl9PRV4IK1yETAOeAl4GZiQlq3OvsYA/5tuazzLJ8OqNI53gQ9IktzJq9jGAmA/kos/C0haevtFxPzViWmFbT8dEatqjT8KjCYZgvUW8BnLn+bX3PywQNKE+vaTdr3cDvw+IiZHxHTgbGC4pLW+yTFY8yFfyDQzy5ZbrGZmGXNiNTPLmBOrmVnGnFjNzDJW1+DyJqd9h/bRvWf3codhDVTlv+9N0qy3ZjF//nzVX7N46tAy+GJVI/VW4d9fPhoRg7Lcf1aaVWLt3rM7Y59p8lN/VpxW1WvXX8lyZ7f+e2S/0S++gv6diqv799n13T1XNs0qsZpZM6BMG8Fl4cRqZvkhoNqJ1cwsW00/rzqxmlmeyF0BZmaZEs1iEKgTq5nli1usZmYZa/p51YnVzHJEQFXTz6xOrGaWL06sZmYZa/p51YnVzHLEXQFmZiXQ9POqE6uZ5YlvEDAzy5a7AszMSsCJ1cwsY00/rzqxmlmOuCvAzKwEmn5edWI1s5zxqAAzs4x52kAzswxJ7mM1M8ucuwLMzDLmrgAzswwJt1jNzDLX9POqE6uZ5YwvXpmZZch3XpmZZU2oyD7WKHEk34QTq5nlihOrmVnGmsGgACdWM8uPpIu1uMy6tLShfCNOrGaWHyq+KyDPnFjNLEdEVVXTv/XKidXMcqUZNFidWM0sP5I7Wpt+ZnViNbP8aCZ9rE2/M8PMmhUV+a/ObUjdJf1D0lRJr0g6PS1vJ2mMpOnp17ZpuSRdKWmGpJckbV+wraFp/emShhZzDE6sZpYrkopa6rEEODMiegMDgFMk9QbOAsZGRC9gbPoeYDDQK12GAdemsbQDzgP6A/2A82qScV2cWM0sV6TilrpExJyImJC+/jcwDdgQGALcmla7FTgwfT0EuC0SzwHrS+oK7AOMiYgPImIhMAYYVN8xuI/VzHJDiOrih1t1kDSu4P0NEXHDStuUNgK2A54HOkfEnHTVe0Dn9PWGwNsFH3snLautvE5OrGaWHw27eDU/Inasc3NSa+A+4GcR8XHhtiMiJJVkygF3BZhZrmTRFZBsR2uQJNU7IuJvafHc9BSf9Ou8tHw20L3g493SstrK6+TEama5UTOO9ZtevFJS4SZgWkT8oWDVCKDmyv5Q4MGC8mPS0QEDgI/SLoNHgb0ltU0vWu2dltXJXQFmlisZjWPdFTgaeFnSpLTsbOB3wD2SjgfeAg5N140C9gVmAIuB4wAi4gNJFwIvpvUuiIgP6tu5E6uZ5UjxE13XJSKepvanZ313FfUDOKWWbd0M3NyQ/Tuxmll+CKqawaNZ3MeaA7Pfns2QvQ9il767s+t2e3D9VcuPGLn6j9fSoWVnFsxfAMCHCz/kmEOPZY8dB7LXbvsw7ZVp5QjbgJNOOJmeG2zMjn37LSv74IMP2G/QAXxrq77sN+gAFi5cCMDDIx6m33YDGLDDLuzWfw+eefqZcoWdW1n1sZabE2sOVLdowQW//y3PTHqK0U+O4qbr/sJr014DkqT7xN+foFv3bsvqX37JFfT5Vh+eHPcE19x0FWefeU65Qq94Pxp6FA88fP9yZZdd8gcG7vltXpo2iYF7fpvLLkmunQzccyDPT3iW58Y/w7U3XsMpJ51ahojzz4nVMtGla2e23e5bALRp05rNt+zFnNnvAXDOr87lvP8+d7n/SK9Ne53dB+4GQK8tevH2W28zb+68lTdsJbfb7rvRrt3ydziOfGgkRx19FABHHX0UD494GIDWrVsv+zkuXrQo98mhXKqkopY8c2LNmVlvzuLlSVPYod/2jHroEbpu0IU+39p6uTp9tunNww+OBGDCixN4e9Y7vDt7zqo2Z2Uwb+77dO3aBYAuXTozb+77y9aNeGAE2/XZnh8OOYRrb7imXCHmV5FjWHOeV0uXWCUtlTSpYNmolnobSZpSqjiakk8+WcSxRxzPxZdeSHWLav54yRWcde5/rlTv9F+exscffszAfnty4zU3sU3fbaiuri5DxFafFU9bDzjwACZOmcDd993JBedfVMbI8kkU1w2Q99Z+KUcFfBoRfUu4/Wblyy+/5LjDf8zBh/+Q/Q78PlOnTGXWm7P49k57AvDu7HfZc8BePPb0aDp36cSfbrwCgIhg+y12YqONe5YzfCvQqXNH5sx5j65duzBnznt07NRhpTq77b4bb848mfnz59Ohw8rrK1mVmv6JdKMdgaTWksZKmiDpZUlDVlFnE0kTJe0kaVNJoyWNl/SUpC0bK9bGFhGcfuIZbL5lL35y+kkA9O7Tm1ffnsrE18cx8fVxbLDhBjz+3Bg6d+nERx9+xBdffAHA8JtvZ+fdBtBm3TblPAQrsO9++3LH8DsAuGP4HXx//+8D8K8Z/yIZLgkTJ0zi888/p3379mWLM6/cYq1bq4I7HmYChwAHpRMhdACekzSiprKkLYC7gWMjYrKkscBJETFdUn/gGmDPEsZbNs8/8wL33HkvvftsxcB+ySH+5oKz2WvQ91ZZ//VXX+eUE05DElv23oIrrru8McO1AkN/dBxP/d9TLJi/gF4bbcE5557Nmb/6OUcfMZTb/jKc7j26M/yuZJa6B+5/kLtuv4sWLdagVauW3HbHLblPEOXQHL4lqvkLmvmGpU8ionXB+zWAy4E9gK+ALYCNgZYk03ktBH4QEVPTGWneB14r2ORaEbHVKvYzjGRiWrp177bDpOnjS3I8Vjqtqtcudwi2GnbrvwcTxk/INA227L5udDt9QFF1//XLMePrm92qXBrzzqujgI7ADhHxpaQ3SZIqwEfALGA3YCpJF8WHxfTRpvMv3gDQd4e+pfkrYWaNJP+n+cVozF7i9YB5aVL9DlB4teUL4CCS2WWOjIiPgZmSDoFlz6PZthFjNbMycR9rw9wBPCTpZWAc8GrhyohYJGk/YIykT0hauNdKOgdYg6T/dXIjxmtmZdAc5gooWWIt7F9N388Hdq6lep+0zofATgXl9T5bxsyaDzWTx197diszyxUnVjOzjDWDvOrEamZ5kv8LU8VwYjWzXHFiNTPLkJrJEwScWM0sV9xiNTPLmhOrmVmWfPHKzCxbTeDpAMVwYjWz3Kh5SmtT58RqZrnixGpmljEPtzIzy1ITmBKwGE6sZpYb7mM1MysBJ1Yzs4w5sZqZZcnjWM3MsiVEVVVjPoqvNJxYzSxX3BVgZpaxZpBXnVjNLEf8MEEzsxJwYjUzy1ZzaLE2/ctvZtZsCFFdVdxS77akmyXNkzSloOx8SbMlTUqXfQvW/VrSDEmvSdqnoHxQWjZD0lnFHIcTq5nlh6BKKmopwi3AoFWUXx4RfdNlFICk3sDhwNbpZ66RVC2pGrgaGAz0Bo5I69bJXQFmlhtZzhUQEU9K2qjI6kOAuyPic2CmpBlAv3TdjIh4gyS2u9O6U+vamFusZpYrVUUu38Cpkl5KuwrapmUbAm8X1HknLautvN5jMDPLjQZ0BXSQNK5gGVbE5q8FNgX6AnOAy0pxDLV2BUj6ExC1rY+I00oRkJlVrgZ2BcyPiB0bsv2ImLtsX9KNwMPp29lA94Kq3dIy6iivVV19rOOKitTMLCsS1SWcK0BS14iYk749CKgZMTACuFPSH4ANgF7ACyS5vpekjUkS6uHAkfXtp9bEGhG3rhDQ2hGxuKEHYmZWLJFd/6Sku4CBJF0G7wDnAQMl9SU5G38TOBEgIl6RdA/JRaklwCkRsTTdzqnAo0A1cHNEvFLfvusdFSBpZ+AmoDXQQ9K2wIkR8ZMGHqeZWb2KHEpVr4g4YhXFN9VR/2Lg4lWUjwJGNWTfxfxx+COwD7Ag3clkYI+G7MTMrFhKn3tV35JnRY1jjYi3VziQpaUJx8wqmciuxVpOxSTWtyXtAoSkNYDTgWmlDcvMKlXTT6vFJdaTgCtIBsW+S9KJe0opgzKzyiSJFpXwBIGImA8c1QixmJnlvv+0GPX+aZC0iaSHJL2fzhTzoKRNGiM4M6s8GU7CUjbFtLnvBO4BupIMnL0XuKuUQZlZZVIDljwrJrGuHRHDI2JJutwOtCx1YGZWmZpDi7WuuQLapS8fSSd3vZvkboXDaOBgWTOz4uQ/aRajrotX40kSac1RnliwLoBflyooM6tMEiWdK6Cx1DVXwMaNGYiZGeS//7QYRd15JakPyWMJlvWtRsRtpQrKzCpTxdx5Jek8khliepP0rQ4GngacWM0sc80hsRbTmXEw8F3gvYg4DtgWWK+kUZlZhSpuApa830RQTFfApxHxlaQlktYF5rH8jNpmZpnIcj7WciomsY6TtD5wI8lIgU+AZ0salZlVJjWPW1qLmSugZkLr6ySNBtaNiJdKG5aZVSJB856ERdL2da2LiAmlCWn1VauKdVq0LncY1kCtBm1e7hBsdUyfV5LNNvcWa12PhQ1gz4xjMbOKJ6qawUjWum4Q+E5jBmJmBs2/xWpm1qik5jGO1YnVzHJFzbkrwMyssQk1i0lYinmCgCT9SNK56fsekvqVPjQzq0TJ5av6lzwrJrprgJ2BI9L3/wauLllEZlbRmvVE1wX6R8T2kiYCRMRCSWuWOC4zq1CVMirgS0nVJGNXkdQR+KqkUZlZRVL6r6krJrFeCdwPdJJ0MclsV+eUNCozq0yVMtwqIu6QNJ5k6kABB0bEtJJHZmYVR0C1qssdxjdWzETXPYDFwEOFZRExq5SBmVklyv9cq8UopitgJF8/VLAlsDHwGrB1CeMyswpVEYk1IrYpfJ/OevWTWqqbmX0jzXoSltpExARJ/UsRjJlVNlEhLVZJPy94WwVsD7xbsojMrHJVyqgAoE3B6yUkfa73lSYcM6tkQs1/VEB6Y0CbiPhFI8VjZhWuWXcFSGoREUsk7dqYAZlZZWvud169QNKfOknSCOBeYFHNyoj4W4ljM7OKk/8JVopRzOxWLYEFJM+42g/YP/1qZpYp8fV8AfX9q3db0s2S5kmaUlDWTtIYSdPTr23Tckm6UtIMSS8VPkxV0tC0/nRJQ4s5jroSa6d0RMAU4OX06yvp1yl1fM7MbLVlOG3gLcCgFcrOAsZGRC9gbPoeYDDQK12GAddCkoiB84D+QD/gvJpkXOcx1LGuGmidLm0KXtcsZmbZkqhSdVFLfSLiSeCDFYqHALemr28FDiwovy0SzwHrS+oK7AOMiYgPImIhMIaVk/VK6upjnRMRF9QbvZlZRkSDxrF2kDSu4P0NEXFDPZ/pHBFz0tfvAZ3T1xsCbxfUeyctq628TnUl1qbfg2xmTU4DhlvNj4gdV3c/ERGSYnU/X5e6ugK+W4odmpnVpbgnXq12u29ueopP+nVeWj4b6F5Qr1taVlt5PcdQi4hYsW/CzKykauYKKGZZTSOAmiv7Q4EHC8qPSUcHDAA+SrsMHgX2ltQ2vWi1d1pWJz/+2sxyREjZPIFV0l3AQJK+2HdIru7/DrhH0vHAW8ChafVRwL7ADJL5p4+DpIEp6ULgxbTeBcU0Op1YzSxXspo2MCKOqGXVSt2cERHAKbVs52bg5obs24nVzHJDgqqMWqzl5MRqZjlSOY9mMTNrNBX5BAEzs1JJRgW4K8DMLEPFTbCSd06sZpYr7mM1M8uYRwWYmWVI+OKVmVm2vtntqrnhxGpmuaKiHmySb06sZpYrbrGamWWo5plXTZ0Tq5nliKj2qAAzs2y5K8DMLENJV4BbrGZmGfJwKzOzzPkGATOzLMl9rGZmmRLNY66Apn8Ezczrr71O/x0GLFs6te3Cn664iot+ezGb9NhsWfnoUaPLHWpF6taxK4//zz288ufHmXLjWE476Pjl1v/84GHEmHdov25bAA7YeW8mXz+Gidc9yotXj2TXrXcCYNtNe/PMFQ8y5caxTL5+DId+e/9GP5Z8UpEPv8536nKLNWc232Jznh//HABLly5l0x6bccCBBzD8luH89PRTOePMn5U5wsq2ZOlSzrz+AibOmELrVusw/ppHGDP+SabNmk63jl3Ze4c9eGvuO8vqj534NCOefQyAbTbeinvOuZatjh/I4s8+5ZhLfsaM2TPp2r4z468exaPj/o+PFn1crkPLjapm0BWQ77Rf4f4x9h9svMkm9OzZo9yhWOq9D+YxccYUAD75dBHTZk1nww5dALj8pPP51Y0XkzzwM7Hos8XLXq/TshVBsm767JnMmD0TgDkL5jLvwwV0XL99Yx1GbtXceVXMvzxzYs2xe+/5K4cefsiy99ddcz07bdePE084iYULF5YxMgPo2bkb223Wh+dfncgBO+/N7AXv8dIb01aqd+Cug5h20xOMvOg2fnzpmSut32mLvqy5xhr86903GyHq/FM6w1V9S56VNLFKWippkqQpkh6StP5qbudYSVdlHV+effHFF4x8aBQ/OPggAP7jpBOY+voUnh//HF26dOGsX/66zBFWtnVars19597Az649nyVLl3D2ET/l3FsuXWXdB/45mq2OH8iB5x/Phcf+crl1Xdp1Yvh/XsFxl565XEu3chXbXq3gxAp8GhF9I6IP8AFwSon312w8Ovox+m63LZ07dwagc+fOVFdXU1VVxY9POI5xL44rc4SVq0V1C+477wbuePx+7n/6ETbtuhEbd+nO5OsfY+bwZ+nWsSsTrh1N57Ydl/vcUy8/zyZdeyy7sNVm7daMvOhWfvOXS3h+2oRyHEruCKhWdVFLnjVmV8CzwIYAkjaVNFrSeElPSdoyLd9f0vOSJkr6u6TOjRhfrtxz973LdQPMmTNn2esHHxhB7623LkdYBtx05qVMmzWDy++7EYApb75K50P7svHRO7Px0Tvzzvtz2P7kQcxd+D6bbrDRss9tt1kf1lpjLRZ8vJA1WqzB/ef/mdvG/JX7nhpZpiPJITWProBGGRUgqRr4LnBTWnQDcFJETJfUH7gG2BN4GhgQESHpBOBXwMqdUstvexgwDKB7j+4lOoLGtWjRIh7/++Ncde2Vy8p+c9Y5vDT5JSTRs2dP/lSwzhrPrlvvxDF7HcxLb0xj4nWPAnD2zb/nkRceX2X9H+6+L8d874d8uXQJn37+GYdddDIAh357f/bYpj/t123LsfscCsCx/3MGk/81tXEOJLfyf5pfDJWyX0fSUuBlkpbqNOA7QCvgfeC1gqprRcRWkrYBLgO6AmsCMyNikKRjgR0j4tS69rfDjtvHP59/OvsDsZJqNWjzcodgq+P5ecTHX2SaBbfqu2XcOubGour277TH+IjYMcv9Z6VR+liBniTdJ6ek+/ww7XutWbZK6/8JuCoitgFOBFqWOD4zyxlfvCpSRCwGTiM5rV8MzJR0CIAS26ZV1wNmp6+HNkZsZpYfHsfaQBExEXgJOAI4Cjhe0mTgFWBIWu184F5J44H5jRWbmeWIVNySYyW9eBURrVd4X3hD9KBV1H8QeHAV5bcAt2QcnpnljprFJCyeK8DMciXvp/nFcGI1s1xxYjUzy5DwRNdmZhnL/xX/YjixmlmuOLGamWVJfjSLmVmmavpYs5iERdKbkl5Opy4dl5a1kzRG0vT0a9u0XJKulDRD0kuStv8mx+HEamY5kvl8rN9Jb5uvmVPgLGBsRPQCxqbvAQYDvdJlGHDtNzkKJ1Yzy5US39I6BLg1fX0rcGBB+W2ReA5YX1LX1d2JE6uZ5UoDugI6SBpXsAxbYVMBPJbO+1yzrnNE1Exu/B5QM+fzhsDbBZ99Jy1bLb54ZWa50oDW6Px6pg3cLSJmS+oEjJH0auHKdN7nksyb6sRqZrmhDOcKiIjZ6dd5ku4H+gFzJXWNiDnpqf68tPpsoHCm/G58PdNeg7krwMxyRkUudWxBWkdSm5rXwN7AFGAEX09JOpSvJ30aARyTjg4YAHxU0GXQYG6xmll+KLNbWjsD96fbagHcGRGjJb0I3CPpeOAt4NC0/ihgX2AGyZzRx32TnTuxmlmuZHHnVUS8AWy7ivIFJM/fW7E8yPAp0k6sZpYrvqXVzCxDIv+Pti6GE6uZ5UpVM7im7sRqZrniFquZWcbcx2pmliH3sZqZlYBbrGZmmXNiNTPLVJW7AszMsubEamaWqaafVp1YzSxX6p+5qilwYjWz3FB2s1uVVdO/d8zMLGfcYjWzXPE4VjOzjDmxmpllzH2sZma2ErdYzSxH5K4AM7PsObGamWWmedwe4MRqZjkjNf1LP06sZpYrbrGamWWu6adWJ1Yzy5Hm8WiWpt+ZYWaWM26xmlluJKMCmn6L1YnVzHLFidXMLGPNoY/VidXMcqR53CLgxGpmudL006oTq5nlTtNPrU6sZpYfzeSZV06sZpYbzWW4lSKi3DFkRtL7wFvljqNEOgDzyx2ENVhz/rn1jIiOWW5Q0miS71kx5kfEoCz3n5VmlVibM0njImLHcsdhDeOfW2XyLa1mZhlzYjUzy5gTa9NxQ7kDsNXin1sFch+rmVnG3GI1M8uYE6uZWcacWM0aiaQe5Y7BGocTaxOj5nC/XwWS1Ak4W9Ivyh2LlZ4TaxMiSZFebZRUJWmNcsdkRfsEeBzoKem0cgdjpeVRAU1Q+ovZB2gD3BAR/yhzSFaLFf4YrgPsA+wNTI2IK8sanJWMW6xNjKRhwAHAb4FOwLFlDchqtUJSbRsRiyLib8AoYGu3XJsvz26Vc5KqIuKrgqKWwDHAYcDnwPGS1gTWj4h55YjRVq0gqZ4CDJb0CvBCRNwnKdKy/4yI35c1UMucE2vO1SRVSUcCk4CNSPrqJkbEvum6k4F1JV0aEUvLFautLD3DOBT4D+D3wF6SOkbEdZLWAnZNW7MLyxqoZcpdATklaYCkXxYUHQG8D5wDfArMS+udAJwKPOCkmi+S2pD8jh1I0rfaiuTnd6ykYRHxV+C/nFSbHyfW/FoCHCfpzPR9G2DDiFgMfB/4lqRbgKOAQyLitfKEaTVWHAoXEf+OiOuAdYHBwOERMQpYABwoaf2I+KQMoVqJuSsgpyJinKSjgeskLQaeBhZL2iAi3pV0LMkEyvIvZz4U9KmeCmwMtAV+B8wF1gS6SNoP+BA4PSI+LFesVloebpUjq7hQhaR+wDXA9sBfgXbAZ+nqIyLi340bpRUqvPKfvj8Z+CEwDLgXeCYifirpv4HeJAn3mIiYXJaArVG4xZoT6S9ozYWqw4DWwBsR8Y+0H/VyYFpEnJfW6eKkmgtrkozOqNGZ5GLVccB7wC/SP5hnS2oFrBkRH5UhTmtE7mPNgTRJFp5GngEsBkZL+lFETALOBI6W9LP0Y3PLE63VkLQ3cLek8yT9MC3eABgN7AAMiYjPgVMknQR85qRaGZxYy0zS94ERkjpJ2pbkNHIQySn/FOACST+JiAnAD4AH4ev+PCsPSYOAC4G/k/weDZbUDrgM6EoyHG5J2hd+MjDWP7PK4a6AMkp/Oc8Czk0H98+T9F2SO6sOiYgd0gtYt0p6L71rx8osTaCjSFqkD0nqBlwM9I6Ip9Of6y2StgZ6AQdHxPQyhmyNzIm1TAp+OX8QEaMlbQb8F3AisA7welp1MfC/wMSyBGoriYgPJO0PXCLp/yLiHUkdgN9JmqSA6ZUAAAPvSURBVAC8ABxOMqwKX/2vPE6sZVLwy3mhpDdILk6NjIjPJM0C1pL0N2ALYP+ImFnOeG15ETFS0lfAeEmjSboDLiOZv+FnwEDgDF9grEweblVm6WnjKODsiPhdWtYC2AbYEpjgwf/5Jel7wGNA14iYm5ZVAe0iYn5Zg7OycWLNAUl7AX8C+vuqcdMjaTBJa3WgJ8Ix8KiAXIiIMSRDrF5I+16tCYmIR4BfkwyP8++UucWaJ5KGAOcBO5KMqPIPpwmR1Nq3Fxs4seaOfznNmj4nVjOzjLk/yMwsY06sZmYZc2I1M8uYE6uZWcacWCuQpKWSJkmaIuleSWt/g23dIung9PWfJfWuo+5ASbusxj7eTO/FL6p8hToNGmEh6XxJv2hojGaFnFgr06cR0Tci+gBfACcVrkxvqW2wiDghIqbWUWUg0ODEatbUOLHaU8BmaWvyKUkjgKmSqiX9j6QXJb0k6URInnQg6SpJr0n6O8mkI6TrnpC0Y/p6kKQJkiZLGitpI5IEfkbaWt5dUkdJ96X7eFHSruln20t6TNIrkv4MiHpIekDS+PQzw1ZYd3laPlZSx7RsU0mj0888JWnLLL6ZZuDZrSpa2jIdTDLjPSTP1eoTETPT5PRRROwkaS3gn5IeA7YjmXGrN8ljSKYCN6+w3Y7AjcAe6bbapbN5XQd8EhGXpvXuBC5P5zDtATwKbEVy99nTEXFBOhH48UUczo/TfbQCXpR0X0QsIJmCcVxEnCHp3HTbpwI3ACdFxHRJ/UmeK7bnanwbzVbixFqZWkmalL5+CriJ5BT9hYLpCfcmecT2wen79Ugmbd4DuCsilgLvSnp8FdsfADxZs62I+KCWOL4H9NbXT41eV1LrdB8/SD87UtLCIo7pNEkHpa+7p7EuAL4imc8W4Hbgb+k+dgHuLdj3WkXsw6woTqyV6dOI6FtYkCaYRYVFwE8j4tEV6u2bYRxVwICI+KywsCDZFUXSQJIkvXNELJb0BNCyluqR7vfDFb8HZllxH6vV5lHgZElrAEjaXNI6wJPAYWkfbFfgO6v47HPAHpI2Tj9bM2PXv4E2BfUeA35a80ZSTaJ7EjgyLRsMtK0n1vWAhWlS3ZKkxVyjCqhpdR9J0sXwMTBT0iHpPqTkeWNmmXBitdr8maT/dIKkKcD1JGc49wPT03W3Ac+u+MGIeB8YRnLaPZmvT8UfAg6quXgFnAbsmF4cm8rXoxN+S5KYXyHpEphVT6yjgRaSpgG/I0nsNRYB/dJj2BO4IC0/Cjg+je8VYEgR3xOzongSFjOzjLnFamaWMSdWM7OMObGamWXMidXMLGNOrGZmGXNiNTPLmBOrmVnG/h8CSEgnx/5S9gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTqJSkXSjXrf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd86a021-5f31-44a8-dd4f-609472ff5c85"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.71      0.74       352\n",
            "           1       0.96      0.97      0.96      2507\n",
            "\n",
            "    accuracy                           0.94      2859\n",
            "   macro avg       0.86      0.84      0.85      2859\n",
            "weighted avg       0.94      0.94      0.94      2859\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeEVemSDRYHJ"
      },
      "source": [
        "**Do Upvote if you find this notebook useful.**\n",
        "\n",
        "**Thanks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP_tyCXFRYHJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}